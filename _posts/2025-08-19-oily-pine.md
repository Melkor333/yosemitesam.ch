# Oily Pine

I want to share a project Iâ€™ve been working on over the last year - I call it `Oily Pine`. The name is just a mix of Oils and Alpine. :) 

**TLDR; Build all [Alpine Linux](https://www.alpinelinux.org/) packages with [Oils for Unix](https://oils.pub/) as shell. Sounds easy, right?**

## Introduction

Oils for Unix (short: *Oils*) is probably the newest POSIX compliant shell out there. Itâ€™s both POSIX *and* Bash compatible, and has some flags to remove â€œclassicalâ€ shell syntax/features in favor of much better designed alternatives that make it a modern shell.

I want to use that modern shell, but not just on my personal servers that I rarely touch. I want to use it every day - on customer systems!
The only way this is going to happen is when Oils becomes a system shell, used by Red Hat, SUSE and maybe even Debian.

Given that Oils is better than Bash in pretty much every way TODO: proof?, I believe this will happen at some point. But Distro maintainers are - for good reason - very stubbornly clinging to their very old and super reliable shells. The shell is deeply embedded into any Unix system, replacing it with â€œthe new kid around the blockâ€ can mess it up in *many* ways.

What we need is a **stable** shell.

### How stable is Oils?

As already pointed out, Oils is both POSIX and Bash compliant. This means any script with either a `#!/bin/sh` or `#!/bin/bash` shebang *should* just work. This sets the bar extremely high - and itâ€™s remarkable how far Andy Chu has pushed the project already. At the end of this blog post youâ€™ll get a bit of an insight into what (known) kinds of bugs are left.

The Oils repo has a *lot* of tests, benchmarks and metrics which are published on each release ([latest](https://oils.pub/release/latest/quality.html)). It's mostly written in typed python that is transpiled to safe, readable C++. There's only a few thousand lines of handwritten C++. Therefore the code is very robust.

But shell - especially Bash - is huge. There is an awful amount of special cases, edge cases - and bugs considered a feature.

This is why Andy has made great efforts to test [real shell programs](https://github.com/oils-for-unix/oils/wiki/Shell-Programs-That-Run-Under-OSH) very early on. But especially in shell - with all their (unnecessary) foot guns - my experience is that people typically learn a unique style of writing their code and then stick to it. Why try out a feature which could shoot you in the foot, when you can achieve the same with 5 messy lines of code you know will work when you copy it from your last script, right?
This became very apparent to me when I went through around 50 Nagios checks from "the internet" with my apprentice last year and tried to apply shellcheck to them. We saw vastly different styles and had to use an unexpected amount of `#shellcheck disable=...`!

There is also a [list of known differences](https://oils.pub/release/latest/doc/known-differences.html). Most of these â€œmissing featuresâ€ are very rarely used and/or foot guns, but our general practice is to try to remove incompatibilities when we â€œspot them in the wildâ€ (and when the Oils codebase allows it...). So if you run into one of these incompatibilities, please [open a ticket](https://github.com/oils-for-unix/oils/issues/new) to make us aware! We canâ€™t fix them all, and this feedback certainly helps us prioritize them.

So I believe we need to *run more shell scripts*! It will happen automatically when people start adopting it, but until then we need to do that work ourselves.

### Searching for Shell Scripts

Shell is a sneaky language. Just recently, I learned that the line `VirusEvent mycommand` in a [Clamav](https://www.clamav.net/) config file will execute the command `$USER_SHELL -c 'mycommand'` when it finds a Virus. Not just `mycommand`. This means I could also do something crazy like `VirusEvent for i in 1 2 3; do echo $i; done; echo "VIRUS!"`! Shell is â€œembeddedâ€ like that in many places. Most prominently in `Makefile`s:

```Makefile
mytarget:
        echo this is shell

secondtarget:
        # We can do the same thing as in the Clamav VirusEvent
        for i in a b c; do echo $1; done
```

Therefore, itâ€™s not a far stretch to start building packages when we want to run a lot of shell.
Not only are there `Makefiles`, but also `configure` scripts written in shell. And Alpine Linux â€œAportsâ€ are even *package definitions* [written in shell](https://gitlab.alpinelinux.org/alpine/aports/-/tree/master/testing/oils-for-unix?ref_type=heads)! Turns out there are testing tools written in shell, too!
So weâ€™ll definitely get a few different styles of shell.

And thatâ€™s why I started that project to build all Aports using Oils as build shell.

> Note: The idea is NOT to make Oils the default shell in Alpine Linux. Alpine is as minimal as possible, and Oils is absolutely no competition against the built-in `busybox ash`. But package definitions and a lot of tooling for Alpine is written in shell, which makes it a great target for testing a shell. Itâ€™s also much easier to bootstrap than e.g. Gentoo - which would make heavy use of shell as well.
> 
> And as a Swiss person, I like Mountains. :p

## The Repository

I started the project by forking the official [Aports repo](https://gitlab.alpinelinux.org/alpine/aports/-/tree/master?ref_type=heads), which contains all the package definitions of the distribution. To make eventual rebasing easy, I created a folder `oily` in the fork, and put everything in there. If youâ€™re curious, [check it out](https://github.com/Melkor333/oily-pine/tree/master/oily) after finishing this post. :)

To build alpine packages, we need to set up a build environment. There are a few platform options for that:
- A virtual machine with Alpine Linux
- An alpine container image
- A `chroot`

When I began the project, I thought using a container is probably the most straight forward way. So thatâ€™s what I did.

### Containers

To build a container image, we need a `Containerfile` (I use Podman, not Docker):

```dockerfile
# oily/container/Containerfile

from alpine:latest

ADD setup-build-env.sh /bin/setup-build-env.sh
RUN setup-build-env.sh

USER packager
WORKDIR /home/packager
VOLUME ["/home/packager/aports"]
VOLUME ["/home/packager/.abuild"]
VOLUME ["/home/packager/logs"]
VOLUME ["/home/packager/packages"]
ENTRYPOINT ["/home/packager/aports/oily/container/package.sh"]
```

This file does not do much:
- Start from alpine linux base container
- Run the `setup-build-env.sh`
- Set some variables on how the container should be executed

The actual doing is in the `setup-build-env.sh`. It downloads and installs Oils (which is in the testing repository), creates a `packager` user, gives him the required permissions and generates a signing-key:

```shell
# oily/container/setup-build-env.sh

# oils-* is only in the testing repos...
echo https://dl-cdn.alpinelinux.org/alpine/edge/testing >> /etc/apk/repositories
apk add abuild abuild-rootbld doas build-base alpine-sdk oils-for-unix oils-for-unix-binsh oils-for-unix-bash lua-aports
# Delete the testing repo again
sed -i '/testing/d' /etc/apk/repositories

# wheel group should be able to run `doas` without password
echo 'permit nopass :wheel' > /etc/doas.conf

adduser -Du 1000 packager
adduser packager abuild
adduser packager wheel
su packager -c "abuild-keygen -na --install"
mkdir -p /home/packager/aports
mkdir -p /home/packager/packages
chown -R packager /home/packager

# Remove the cache of installed packages to make the container smaller
apk cache clean --purge
```

### The Oils Package

My script installs 3 packages:
- oils-for-unix
- oils-for-unix-binsh
- oils-for-unix-bash

This is because I was [very considerate](https://gitlab.alpinelinux.org/alpine/aports/-/merge_requests/70331) when creating the package definition:

`oils-for-unix` creates a binary `/usr/bin/oils-for-unix` and 2 symlinks `/usr/bin/osh` and `/usr/bin/ysh`. `osh` starts a bash-compatible shell, while `ysh` starts Oils with all the feature flags for a modern shell enabled.

> This usage of symlinks to change behaviour is nothing special. Most shells will behave differently when executed as `/bin/sh` instead of e.g. `/bin/bash` or `/bin/zsh`. Vim has compat mode enabled when executed with `/bin/vi` instead of `/bin/vim`, etc.

`oils-for-unix-binsh` provides a â€œvirtual packageâ€ called `/bin/sh` (like `busybox-binsh` does) and thus effectively *replaces* the symlink `/bin/sh -> /bin/busybox` with a symlink `/bin/sh -> /usr/bin/oils-for-unix`. Again, the Oils binary is POSIX compliant when executed via the symlink `sh`.

> â€œVirtual packagesâ€ in Alpine Linux are great for declaring multiple packages providing the same thing. When a package definition provides a virtual package, it also needs to define a priority:
> ```shell
> # additional definitions of subpackage oils-for-unix-binsh
> provides="/bin/sh"
> provider_priority=10 # lowest (other providers: dash-binsh, busybox-binsh, yash-binsh)
> ```
> Now if I do `apk add /bin/sh` it will install the package with highest priority, that is `busybox-binsh`. If I follow up with `apk add oils-for-unix-binsh` it will remove `busybox-binsh` before it installs my package.

`oils-for-unix-bash` indirectly *conflicts* with the `bash` package, as it creates a symlink `/bin/bash -> /usr/bin/oils-for-unix`. We canâ€™t create a virtual package `bash` here, because `bash` is already a non-virtual package. But as weâ€™ll see later on, both packages implicitly provide the package `cmd:bash` that we can use.

### Container Volumes

Now remember the last line in the Containerfile?:

```dockerfile
ENTRYPOINT ["/home/packager/aports/oily/container/package.sh"]
```

It points to a script which should be executed when we start the container. This script does only 2 things:

```shell
# oily/container/package.sh

# Make sure the apk signing key is available, and reuse an existing key
../setup-key.sh

# Build all packages
buildrepo -k -l "$HOME/logs" $@ main
buildrepo -k -l "$HOME/logs" $@ community
buildrepo -k -l "$HOME/logs" $@ testing
```

`buildrepo` is a (shell) script written by the Alpine folks to build a whole set of package definitions. But where are these definitions?
And you mightâ€™ve asked yourself, how does the `package.sh` make it into the container?!

When I started out, I had an `ADD` statement in the `Containerfile` to copy the `package.sh` into the container image and use `ENTRYPOINT ["/package.sh"]`. But that meant whenever I changed the script, I had to build another image. 

At the same time I didnâ€™t want to have a huge image containing all package definitions, so I mounted the repository root to the directory `/home/packager/aports`, where `buildrepo` expects the package definitions! So the file `/home/packager/aports/oily/container/package.sh` is always available in the container anyway. Therefore I changed the `ENTRYPOINT` after some time while putting this stuff together.

I added 3 more mount points, one to be able to reuse the same signing-key, one for logs and one for finished packages:

```dockerfile
VOLUME ["/home/packager/aports"]
VOLUME ["/home/packager/.abuild"]
VOLUME ["/home/packager/logs"]
VOLUME ["/home/packager/packages"]
```

And the actual command to run the container looks like this:

```shell
# heavily simplified version of oily/container.sh

cd $GIT_ROOT

package() {
  podman run --rm \
  -v ./:/home/packager/aports \
  -v ./oily/abuild:/home/packager/.abuild \
  -v ./oily/logs:/home/packager/logs \
  -v ./oily/packages:/home/packager/packages \
  oily-pine-builder $@
}
```


For a bit of an overview, the file hierarchy of the git repo is like this:
- oily-pine
  - main/ `# package definitions of the main repo`
  - community/ `# package definitions of the community repo`
  - testing/ `# package definitions of the testing repo`
  - oily/
    - container.sh `# Holds functions to build/run the container`
    - container/
      - Containerfile
      - Dockerfile `# A softlink to the Containerfile so it works with Docker and Podman`
      - setup-build-env.sh
      - package.sh
    - abuild `# Keeps the abuild.conf file and key between executions`
    - logs `# This is where our build logs will go`
    - packages `# This is where finished packages will go. We could also throw them away...`

## Letâ€™s Build Some Packages

Letâ€™s build and run that Container! I had some issues with IPv6, so I told podman to use the host network: 

```shell
$ # This runs basically one command:
$ # podman build --network=host oily/container/ -t oily-pine-builder
$ ./oily/container.sh build
...
COMMIT oily-pine-builder
--> 1fed23b134a1
Successfully tagged localhost/oily-pine-builder:latest
1fed23b134a19c77aae25b0591f948d803218cbaa31ada757eb99d3688515ffa
$
$ ./oily/container.sh run
/home/packager
using /home/packager/.abuild/-682737bd.rsa
pigz: not found
1/1579 1/1580 main/acf-jquery 0.4.3-r2
oils: PID 238 exited, but oils didn't start it
oils: PID 258 exited, but oils didn't start it
oils: PID 263 exited, but oils didn't start it
oils: PID 265 exited, but oils didn't start it
oils: PID 261 exited, but oils didn't start it
2/1579 2/1580 main/zlib 1.3.1-r2
oils: PID 594 exited, but oils didn't start it
3/1579 3/1580 main/perl 5.40.2-r0v
4/1579 4/1580 main/linux-headers 6.14.2-r0
...
18/1579 18/1580 main/expat 2.7.1-r0
ERROR: expat: Failed to build
19/1579 18/1580 main/gdbm 1.24-r0
...
 ```

**WEâ€™RE BUILDING!**

Now there were [*A LOT* more](https://github.com/Melkor333/oily-pine-logs/blob/master/25-05-16_15%3A04-buildrepo.log) of these `oils didn't start it` warnings, but who cares, the packages built successfully. :)
The above snippet also shows how it looks when package 18 - `expat` - fails.

I was so excited about these package builds that I wrote a script which monitored the output and sent me an hourly update to my phone with [ntfy](https://ntfy.sh/):

![Notifications on the phone showing increasing number of packages](assets/images/2025-08-15_11-45-29-oils-notifications.png)
I think it was compiling GCC between 00:00-06:00 that day, which just took some time on my very old server.

The builds ran. They had to be restarted a few times due to different issues like an actual infinite loop and I changed it slightly to build main, test and community at the same time. But the number of packages kept growing.

After about 10 days the allocated 500GB disk filled up with 11999 built packages, and 1173 failed Aports. Every failed aport left the build sources behind, which used up all the disk space. The built `apk`s were only a few GB in size.
Anyway, 90% success rate in a first attempt isnâ€™t too bad. I hoped for 95%, but 90% still seemed OK, given that a single bug in e.g. `autoconfigure` could be hit by many packages. Right?

### Wrong!

I compared apples with oranges:

> 11999 built *packages*, with 1173 failed *aports*

Aport means â€œpackage definitionâ€. Package means â€œ*.apk fileâ€.

A single Aport can contain many packages. The Oils Aport I described above has 3 package definitions, not counting autogenerated debug and doc packages!

While I documented the amount of successful Aports for community (1293) and testing (2960), I never noted down how many Aports succeeded in the `main` repo except for â€œover 500 failuresâ€ (out of 1580), that means I canâ€™t give clear numbers. I also somehow lost the original logs listing all packages...
The most precise I get is â€œless than 5333â€ successful packages (2960 + 1293 + 1580 - 500). 5333 successes with 1173 failures is what, barely 82%?

Iâ€™m not sure if I wouldâ€™ve continued the same way I did if I had realized that earlier. I guess it doesnâ€™t really matter.

## Analyze and Categorize

Oblivious of that fact, I started looking into logs and tried to find actual Oils bugs. And I definitely found bugs, which youâ€™ll see later.

The process of analyzing a single log file requires... TIME! And I was sure weâ€™re hitting the same bugs various times. At the same time, if a bug occurs in 100 builds, weâ€™d rather focus on that than another one happening in a single package build.

So after taking a look at around 10 log files, I decided to find a way to quickly *categorize* the logs of the >1000 failed builds. And what could be better to churn through so much text than a machine? AI?! Iâ€™ve never had a real â€œI *need* AI for thatâ€ use case, but this sounded like the perfect opportunity! Iâ€™ll never be able to look at so many logs myself anyway.

So I whipped up a small script to send the last 40 log lines of a file to ChatGPT and try to summarize the problem in *maximum 5 words*. Sorry for throwing ysh at you, but it shouldnâ€™t be too hard to understand. For some reason I didnâ€™t want to use bash for this:

```bash
# simplified categorization-script

#!/usr/bin/env ysh

# *some preparation*

for file in (bad_files => split(u'\n')) {
  ... cat ./PROMPT_TEMPLATE.md
      # Ignore all lines from abuild removing packages at the end
    <(... grep -v "Purging" $file | head -n -1
      # the error should be in the last few lines.
      # chatgpt can't handle too much input!
      | tail -40
      ;)
    | chatgpt
    | tr -d u'\n'
    >> $out_file

  # Add a newline
  echo >> $out_file
}
````

`...` allows me to spread a single command to multiple lines without the need of `\` at the end and the possibility to add comments in-between (I love Oils for this!). The script concatenates the following `PROMPT_TEMPLATE.md` and 40 lines of the logfile, send them to chatgpt and remove any newlines in the chatgpt output (which shouldnâ€™t be more than 5 words!!1!)

Iâ€™m not a prompt Engineer. So I just copied a prompt from #internet and adjusted it to fit my need:

```markdown
# IDENTITY and CATEGORY
You are a genius error message categorization expert and you are able to understand and categorize errors from software being compiled for Linux.
You specialize in extracting the relevant error messages from a log file and create a very brief category for the error.
Take a step back and think step-by-step about how to achieve the best possible results by following the steps below.

You have no knowledge on what to do with the error message. Your only purpose is to categorize it.

# STEPS
Read the entire log file from an attempted package compilation, trying to identify the exact log line containing the error message which causes the build to fail.
Come up with a description of this error type which is not more than 5 words, to be used as CATEGORY-DESCRIPTION.

# OUTPUT INSTRUCTIONS
Only output a single line of plain text.

Do not give warnings or notes; only output the requested 5 words.
Do not try to give a solution to the error.
You can only output a single sentence of 5 words.
Ensure you follow ALL these instructions when creating your output.

# INPUT
Logs:
```

And it worked (mostly)! :)
I only categorized the >500 failed packages from the `main` repo to not spend too much money initially. Then I created some stats to see how often Chatgpt used the same â€œ5â€ words. The top 10 looked like this:

```
    179 c compiler cannot create executables.
     29 phdr segment not covered by load segment.
     13 phdr segment not covered error.
      9 compiler-executable creation error.
      9 c compiler unable to create executables.
      8 c compiler cannot create executables
      7 compiler cannot compile programs.
      7 builddeps failed due to conflicts.
      6 phdr segment not covered by load segment
      6 linker input file not found.
```

Well that was surprising! Apparently there are only 2 major issues, a c compiler issue and a â€œphdr segmentâ€ issue. I tried to reproduce this immediately bz building a package by hand. The package built perfectly! I successfully built a bunch of packages by hand, which led me to the conclusion that something must be broken in the container. 

I thought about this for a while and found out that `abuild` has an option called `rootbld`, which builds a package inside a [bubblewrap sandbox](https://github.com/containers/bubblewrap) (which is more or less a chroot). `buildrepo` (the tool I use in `package.sh` to build all packages) supports this, too.

Given that Iâ€™ve also seen a few packages fail because they couldnâ€™t spawn a (nested) container for tests, I thought that maybe using the official tooling could solve that issue as well. At the same time, Andy and me discussed my project and how long it took to build the packages, so he agreed to use the Github Sponsors money we gained over the years for some rented hardware to speed up the process.

> Andy saw that the Oils project could gain a lot of stability from the project, which made me really happy! From the very beginning he was super supportive and thankful for all the work I did. Itâ€™s a real pleasure to work on a project with him.

## Alpine Linux + Rootbld

To potentially fix both the nested container and the phdr/c compiler issues - and to lean a bit more into alpine upstream tooling - I decided to create a big Alpine Linux VM when I got access to the physical Server. And so I began making everything ready to build packages with Oils in a bubblewrap chroot directly on Alpine.

Configuring the VM itself didnâ€™t require much more than running the `setup-build-env.sh` script.

Abuild sets up a chroot directory by installing a bunch of packages into a temporary directory. This command needed to be adjusted to also install the Oils package:

```shell
# abuild command to prepare the build environment

echo "installing oils!"
$SUDO_APK add --initdb --update \
      --no-interactive \
      --arch $CBUILD_ARCH \
      --root "$BUILD_ROOT" \
      ${cachedir:+--cache-dir $cachedir} \
      abuild alpine-base build-base git $hostdeps $builddeps oils-for-unix-binsh \
      ${USE_CCACHE:+ccache}
```

All I had to do was add `oils-for-unix-binsh`. Thatâ€™s it!

Notice that this time I didnâ€™t install `oils-for-unix` or `oils-for-unix-bash`. `oils-for-unix-binsh` depends on `oils-for-unix`, so I donâ€™t need to explicitly specify that anyway. And I decided to not replace `/bin/bash` *yet*...

### Stonks?!

...because Andy â€œsecuredâ€ another NLNet Grant!

> The [NLNet Foundation](https://nlnet.nl/) has various programs to fund projects that contribute to an open internet for all.
> The Oils project has already been able to vastly improve different parts with 3 prior funds. For example the garbage collector built into Oils was mostly funded with the second grant. And the last grant was used to make the docs much more usable, as well as adding a lot more spec tests (and builtins) for ysh.

In the second quarter of this year, Andy filled in the form for the fourth grant with the objective of stabilizing the Shell/Bash compatible part of the project. And believing in my work, he wanted to base it off of this project! ðŸ¤©

We hope to attract more contributors with the grant, but apparently it requires a very niche mindset to work on a shell and/or the onboarding to the Oils codebase is too hard. The previous grants never attracted more than 1-2 people... (I also didnâ€™t join the project because of a grant.)

> If **you** are interested, please hit us up on [zulip](https://oilshell.zulipchat.com/). Weâ€™re still having a bit of a hard time understanding what keeps people from joining, so weâ€™re especially interested in knowing what keeps you from jumping on board!

The idea is to use the grant to find and fix bugs - with the help of oily-pine!
The â€œevent loopâ€ is basically:
- analyze why package X doesnâ€™t build
- reduce the bug to a simple spec test
- fix it

> BTW. Iâ€™m terrible at the last part. Iâ€™m a Systems Engineer, not a Developer! But luckily, there are people like Andy - or Koichi as youâ€™ll see - who can fix them. :)

To keep the scope reasonable, we decided to only focus on the `main` repo in the beginning, and only replace `/bin/sh`. We do think POSIX is a good first milestone before getting to Bash. If we succeed with this goal fast, then itâ€™s easy to extend the scope to Bash and the testing/community repositories.

## Categorical

I digressed... Apart from adding `oils-for-unix-binsh` to `abuild`, the build with `rootbld` in an Alpine Linux VM doesnâ€™t involve anything special. I cloned the repo to `/home/packager/aports`, ran the `setup-build-env.sh` script from the beginning and then ran the command `buildrepo -k -l "$HOME/logs" main`.

This time I successfully built 1330/1580 packages (250 failures) in not even a day! The new server was really worth it.

Now I wanted to manually categorize the failed packages, so I wrote a [small script](https://github.com/Melkor333/oily-pine/blob/9cb57f0efc7a96d4c98e337f6d7f9802c57ca419/oily/logs.ysh#L49) which showed me the error log, gave me an FZF prompt to select an existing category and when I pressed `ctrl+c` it asked for a new category. In around 2 hours of manual work the second categorization was done.

> Fun fact: I did most of the categorizations on the phone using [Juicessh](https://juicessh.com/) when I was in the train, on the toilet or walking my baby to sleep in the baby carrier. Not only that, but most of the work was done on my phone. I have several projects that mostly inside of a [Termux](https://termux.dev/en/) terminal, but for this one I needed a proper server.

I created a repository to keep the logs (and hopefully donâ€™t lose them again), you can find them [on github](https://github.com/Melkor333/oily-pine-logs).
And this is how the summary looked like:

```
     59 ifs=\\
     37 broken testsuite
     29 abuild - cant fetch package index
     25 cmake error - compatibility unsupported
     15 libtool invalid word while parsing
     15 build timeout
     11 mkdir: unrecognized option: /
     10 config.status compile error
     10 abuild dependency issue (e.g. depends on busybox-binsh)
      9 abuild - fetch source issue
      6 (( .. ) .. )
      5 atf-test-program fail
      3 OSH command not found
      1 unexpected rustc version (alpine issue?)
      1 print oils ast error
      1 osh printf doesn't support single characters
      1 ninja build failure
      1 missing header file
      1 missing FNM_EXTMATCH support in libc
      1 meson test - test must be compiled first
      1 meson test - file not found
      1 libtool unrecognized macro
      1 couldn't fetch source during build
      1 configure: error: can't find a separator character in '+,;&' for the path_replacer shell script
      1 configure.ac terminate called after throwing an instance of 'IndexError*'
      1 config.status (test) Unexpected trailing word '--'
      1 compile time error
      1 Makefile Error 1
      1 'trap' requires a signal or hook name
250 /home/packager/oily-pine/oily/logs/issues
```


Some of these categories donâ€™t seem like Oils bugs, and especially 2 of them I immediately fixed:
- `29 abuild - cant fetch package index`
  - This happened due to a network issue, `abuild` couldnâ€™t download the source for the package
  - The fix was to just rerun the builds :)
- `15 build timeout`
  - As already pointed out, there was an infinite loop. So I set an arbitrary timeout of 1800 seconds in the `buildrepo` shell script. It just executes `abuild` for every package and I changed it to `timeout 1800 abuild`
  - I just reran them with a timeout of 18000 seconds, which allowed the GCC, Node, LLVM, etc. to build but still stopped the infinite loops at some point

With these things fixed I did another categorization. The top ten only slightly changed. Most importantly I now know that there are 4 packages which all use `gpgrt-config` and run into the same bug :)

```
     59 ifs=\\
     39 broken testsuite
     25 cmake error - compatibility unsupported
     15 libtool invalid word while parsing
     11 mkdir: unrecognized option: /
     10 config.status compile error
     10 abuild dependency issue (e.g. depends on busybox-binsh)
      9 abuild - fetch source issue
      6 (( .. ) .. )
      5 atf-test-program fail
      4 gpgrt-config timeout
      ...
```

Now itâ€™s *finally* time to look into bugs! ðŸŽ‰ðŸŽ‰ðŸŽ‰

# ChÃ¤ferfescht

> ChÃ¤ferfescht is a swiss term that literally translates to â€œbug partyâ€. It is used to describe a small irrelevant event. â€œYouâ€™re really going to this party? What a chÃ¤ferfeschtâ€

The top issue `ifs=\\` is a known bug in Oils I already found in 2024 when I tried to build nixpkgs with Oils ([zulip thread](https://oilshell.zulipchat.com/#narrow/channel/307442-nix/topic/mpfr.20package.20build.20failure.20-.20DLT_OBJDIR/with/477522248)). Itâ€™s *really hard to fix* thus required a [(still open) PR](https://github.com/oils-for-unix/oils/pull/2353) from a [nuclear physicist](https://akinomyoga.github.io/). ðŸ˜›

> Koichi Murase is the author of one of the biggest bash scripts - [the line editor ble.sh](https://github.com/akinomyoga/ble.sh) - has sent patches to Bash and has been active in the Oils zulip chat for a long time. He also fixed various bash incompatibilities and added some bash specific features.

Weâ€™re very glad that at least for the `main` repo, we already almost fixed the biggest bug!
